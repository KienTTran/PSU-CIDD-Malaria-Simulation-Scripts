name: Upload generator func
inputs:
- {name: pipeline_config}
outputs:
- {name: remote_files, type: JsonArray}
implementation:
  container:
    image: python:3.8
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'pyaml' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'pyaml' --user) && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp)
      printf "%s" "$0" > "$program_path"
      python3 -u "$program_path" "$@"
    - "def upload_generator_func(pipeline_config):\n    import yaml\n    import os\n\
      \    from collections import namedtuple\n\n    params = 0\n    print(\"Reading\
      \ \" + pipeline_config)\n    with open(pipeline_config,'r') as file:\n     \
      \   params =  yaml.full_load(file)\n\n    generator_build_parameters = params['generator']['build']['parameters']\n\
      \    generator_build_parameter_str = ''\n    if generator_build_parameters !=\
      \ None:\n        for parameter in generator_build_parameters:\n            generator_build_parameter_str\
      \ += ' ' + str(generator_build_parameters)\n\n    generator_config_parameters\
      \ = params['generator']['config']['parameters']\n    generator_config_parameter_str\
      \ = ''\n    if generator_config_parameters != None:\n        for parameter in\
      \ generator_config_parameters:\n            generator_config_parameter_str +=\
      \ ' ' + str(parameter)\n\n    cluster_username = params['ssh']['username']\n\
      \    cluster_home_path = \"/storage/home/\" + cluster_username[0] + \"/\" +\
      \ cluster_username\n    upload_file_pairs = params['remote']['files']\n\n  \
      \  cluster_path_src = []\n    cluster_path_dst = []\n    cluster_path_mkdir\
      \ = []\n    for pair in upload_file_pairs:\n        if type(pair) == str:\n\
      \            cluster_path_mkdir.append(os.path.join(cluster_home_path,pair))\n\
      \        else:\n            for key in pair.keys():\n                path =\
      \ key\n                src_files = pair[key]\n                cluster_path_mkdir.append(os.path.join(cluster_home_path,path))\n\
      \                for src_file in src_files:\n                    cluster_file_dst_path\
      \ = os.path.join(cluster_home_path,path)\n                    cluster_path_dst.append(cluster_file_dst_path)\n\
      \                    cluster_path_src.append(src_file)\n                   \
      \ print(src_file + ' --> ' + cluster_file_dst_path)\n\n    remote_path_output\
      \ = namedtuple('outputs', ['remote_files'])  \n    cluster_file_list = []\n\
      \    for file_path in cluster_path_src:\n        print('Cluster file path (transfer\
      \ from): ' + file_path)  \n    cluster_file_list.append(cluster_path_src)\n\
      \    for file_path in cluster_path_dst:\n        print('Cluster file path (transfer\
      \ to): ' + file_path)\n    cluster_file_list.append(cluster_path_dst)\n    for\
      \ file_path in cluster_path_mkdir:\n        print('Cluster file path (create):\
      \ ' + file_path)\n    cluster_file_list.append(cluster_path_mkdir)\n\n    return\
      \ remote_path_output(cluster_file_list)\n\ndef _serialize_json(obj) -> str:\n\
      \    if isinstance(obj, str):\n        return obj\n    import json\n\n    def\
      \ default_serializer(obj):\n        if hasattr(obj, 'to_struct'):\n        \
      \    return obj.to_struct()\n        else:\n            raise TypeError(\n \
      \               \"Object of type '%s' is not JSON serializable and does not\
      \ have .to_struct() method.\"\n                % obj.__class__.__name__)\n\n\
      \    return json.dumps(obj, default=default_serializer, sort_keys=True)\n\n\
      import argparse\n_parser = argparse.ArgumentParser(prog='Upload generator func',\
      \ description='')\n_parser.add_argument(\"--pipeline-config\", dest=\"pipeline_config\"\
      , type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      ----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args\
      \ = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\"\
      , [])\n\n_outputs = upload_generator_func(**_parsed_args)\n\n_output_serializers\
      \ = [\n    _serialize_json,\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n\
      \    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n\
      \        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --pipeline-config
    - {inputPath: pipeline_config}
    - '----output-paths'
    - {outputPath: remote_files}
